<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>CS 224N  | Home</title>

</head>

<body>
<!-- Content -->
<div class="container sec" id="content">
  <h2>Natural Language Processing with Deep Learning</h2>
<li>
        <a href="https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1194/index.html#schedule">CS224N-2019</a>
</li>
<li>
        <a href="https://web.stanford.edu/class/cs224n/index.html">CS224N</a>
</li>
<li>
  <a href="https://m.youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z">Playlist</a>
</li>

  <h3>What is this course about?</h3>
  <p>
    Natural language processing (NLP) is one of the most important technologies of the information age, and a crucial part of artificial intelligence.
    Applications of NLP are everywhere because people communicate almost everything in language: web search, advertising, emails, customer service, language translation, virtual agents, medical reports, etc.
    In recent years, Deep Learning approaches have obtained very high performance across many different NLP tasks, using single end-to-end neural models that do not require traditional, task-specific feature engineering.
    In this course, students will gain a thorough introduction to cutting-edge research in Deep Learning for NLP.
    Through lectures, assignments and a final project, students will learn the necessary skills to design, implement, and understand their own neural network models.
    This year, CS224n will be taught for the first time using <a href="https://pytorch.org"><b>PyTorch</b></a> rather than TensorFlow (as in previous years).
  </p>


<!-- Schedule -->
<!-- Note the margin-top:-20px and the <br> serve to make the #schedule hyperlink display correctly (with the h2 header visible) -->
<div class="container sec" id="schedule" style="margin-top:-20px">
<br>
<h2>Schedule</h2>
<p>
  Lecture <b>slides</b> will be posted here shortly before each lecture. If you wish to view slides further in advance, refer to <a href="https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1184/syllabus.html">last year's slides</a>, which are mostly similar.
</p>
<p>
  The lecture <b>notes</b> are updated versions of the CS224n 2017 lecture notes (viewable <a href="https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1174/syllabus.html">here</a>) and will be uploaded a few days after each lecture. The notes (which cover approximately the first half of the course content) give supplementary detail beyond the lectures.
</p>
<p>
  <em>This schedule is subject to change</em>.
</p>
<table class="table">
  <colgroup>
    <col style="width:10%">
    <col style="width:20%">
    <col style="width:40%">
    <col style="width:10%">
    <col style="width:10%">
  </colgroup>
  <thead>
  <tr class="active">
    <th>Date</th>
    <th>Description</th>
    <th>Course Materials</th>
    <th>Events</th>
    <th>Deadlines</th>
  </tr>
  </thead>
  <tbody>
  <tr>
    <td>Tue Jan 8</td>
    <td>Introduction and Word Vectors
      <br>
      [<a href="slides/cs224n-2019-lecture01-wordvecs1.pdf">slides</a>]
      [<a href="https://youtu.be/8rXD5-xhemo">video</a>]
      [<a href="readings/cs224n-2019-notes01-wordvecs1.pdf">notes</a>]
      <br><br>
      Gensim word vectors example:
      <br>
      [<a href="materials/Gensim.zip">code</a>]
      [<a href="materials/Gensim%20word%20vector%20visualization.html">preview</a>]
    </td>
    <td>
      Suggested Readings:
      <ol>
        <li>
		<a href=http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/>Word2Vec Tutorial - The Skip-Gram Model</a>
                <a href=https://math-papers.github.io/2024/(240730)%20Word2Vec%20Tutorial%20-%20The%20Skip-Gram%20Model.pdf>[pdf ⬇️]</a>
	</li>
        <li><a href="http://arxiv.org/pdf/1301.3781.pdf">Efficient Estimation of Word Representations in Vector Space</a> (original word2vec paper)</li>
        <li><a href="http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf">Distributed Representations of Words and Phrases and their Compositionality</a> (negative sampling paper)</li>
      </ol>
    </td>
    <td>
      Assignment 1 <b><font color="green">out</font></b>
      <br>
      [<a href="assignments/a1.zip">code</a>]
      [<a href="assignments/a1_preview/exploring_word_vectors.html">preview</a>]
    </td>
    <td></td>
  </tr>

  <tr>
    <td>Thu Jan 10</td>
    <td>Word Vectors 2 and Word Senses
      <br>
      [<a href="slides/cs224n-2019-lecture02-wordvecs2.pdf">slides</a>]
      [<a href="https://youtu.be/kEMJRjEdNzM">video</a>]
      [<a href="readings/cs224n-2019-notes02-wordvecs2.pdf">notes</a>]
    </td>
    <td>
      Suggested Readings:
      <ol>
        <li><a href="http://nlp.stanford.edu/pubs/glove.pdf">GloVe: Global Vectors for Word Representation</a> (original GloVe paper)</li>
        <li><a href="http://www.aclweb.org/anthology/Q15-1016">Improving Distributional Similarity with Lessons Learned from Word Embeddings</a></li>
        <li><a href="http://www.aclweb.org/anthology/D15-1036">Evaluation methods for unsupervised word embeddings</a></li>
      </ol>
      Additional Readings:
      <ol>
      	<li><a href="http://aclweb.org/anthology/Q16-1028">A Latent Variable Model Approach to PMI-based Word Embeddings</a></li>
      	<li><a href="https://transacl.org/ojs/index.php/tacl/article/viewFile/1346/320">Linear Algebraic Structure of Word Senses, with Applications to Polysemy</a></li>
      	<li><a href="https://papers.nips.cc/paper/7368-on-the-dimensionality-of-word-embedding.pdf">On the Dimensionality of Word Embedding.</a></li>
      </ol>
    </td>
    <td></td>
    <td></td>
  </tr>

  <tr class="warning">
    <td>Fri Jan 11</td>
    <td>Python review session
      <br>
      [<a href="readings/python-review.pdf">slides</a>]
    </td>
    <td>
      1:30 - 2:50pm<br>Skilling Auditorium [<a href="https://maps.google.com/maps?hl=en&q=Skilling%20Auditorium%2C%20494%20Lomita%20Mall%2C%20Stanford%2C%20CA%2094305%2C%20USA">map</a>]
    </td>
    <td></td>
    <td></td>
  </tr>

  <tr>
    <td>Tue Jan 15</td>
    <td>Word Window Classification, Neural Networks, and Matrix Calculus
      <br>
      [<a href="slides/cs224n-2019-lecture03-neuralnets.pdf">slides</a>]
      [<a href="https://youtu.be/8CWyBNX6eDo">video</a>]
      <br>
      [<a href="readings/gradient-notes.pdf">matrix calculus notes</a>]
      <br>
      [<a href="readings/cs224n-2019-notes03-neuralnets.pdf">notes (lectures 3 and 4)</a>]
    </td>
    <td>
      Suggested Readings:
      <ol>
        <li><a href="http://cs231n.github.io/optimization-2/">CS231n notes on backprop</a></li>
        <li><a href="readings/review-differential-calculus.pdf">Review of differential calculus</a></li>
      </ol>
      Additional Readings:
      <ol>
      	<li><a href="http://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf">Natural Language Processing (Almost) from Scratch</a></li>
      </ol>
    </td>
    <td>
      Assignment 2 <b><font color="green">out</font></b>
      <br>
      [<a href="assignments/a2.zip">code</a>]
      [<a href="assignments/a2.pdf">handout</a>]
    </td>
    <td>Assignment 1 <b><font color="red">due</font></b></td>
  </tr>

  <tr>
    <td>Thu Jan 17</td>
    <td>Backpropagation and Computation Graphs
      <br>
      [<a href="slides/cs224n-2019-lecture04-backprop.pdf">slides</a>]
      [<a href="https://youtu.be/yLYHDSv-288">video</a>]
      <br>
      [<a href="readings/cs224n-2019-notes03-neuralnets.pdf">notes (lectures 3 and 4)</a>]
    </td>
    <td>
      Suggested Readings:
      <ol>
        <li><a href="http://cs231n.github.io/neural-networks-1/">CS231n notes on network architectures</a></li>
        <li><a href="http://www.iro.umontreal.ca/~vincentp/ift3395/lectures/backprop_old.pdf">Learning Representations by Backpropagating Errors</a></li>
        <li><a href="http://cs231n.stanford.edu/handouts/derivatives.pdf">Derivatives, Backpropagation, and Vectorization</a></li>
        <li><a href="https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b">Yes you should understand backprop</a></li>
      </ol>
      </td>
      <td></td>
      <td></td>
  </tr>

  <tr>
    <td>Tue Jan 22</td>
    <td>Linguistic Structure: Dependency Parsing
      <br>
      [<a href="slides/cs224n-2019-lecture05-dep-parsing.pdf">slides</a>]
      [<a href="slides/cs224n-2019-lecture05-dep-parsing-scrawls.pdf">scrawled-on slides</a>]
      <br>
      [<a href="https://youtu.be/nC9_RfjYwqA">video</a>]
	    [<a href="readings/cs224n-2019-notes04-dependencyparsing.pdf">notes</a>]
     </td>
    <td>
      Suggested Readings:
      <ol>
        <li><a href="https://www.aclweb.org/anthology/W/W04/W04-0308.pdf">Incrementality in Deterministic Dependency Parsing</a></li>
        <li><a href="http://cs.stanford.edu/people/danqi/papers/emnlp2014.pdf">A Fast and Accurate Dependency Parser using Neural Networks</a></li>
        <li><a href="http://www.morganclaypool.com/doi/abs/10.2200/S00169ED1V01Y200901HLT002">Dependency Parsing</a></li>
        <li><a href="https://arxiv.org/pdf/1603.06042.pdf">Globally Normalized Transition-Based Neural Networks</a></li>
        <li><a href="http://nlp.stanford.edu/~manning/papers/USD_LREC14_UD_revision.pdf">Universal Stanford Dependencies: A cross-linguistic typology</a></li>
        <li><a href="http://universaldependencies.org/">Universal Dependencies website</a></li>
      </ol>
    </td>
    <td>Assignment 3 <b><font color="green">out</font></b>
        <br>
        [<a href="assignments/a3.zip">code</a>]
        [<a href="assignments/a3.pdf">handout</a>]
    </td>
    <td>Assignment 2 <b><font color="red">due</font></b></td>
  </tr>

  <tr>
    <td>Thu Jan 24</td>
    <td>The probability of a sentence? Recurrent Neural Networks and Language Models
      <br>
      [<a href="slides/cs224n-2019-lecture06-rnnlm.pdf">slides</a>]
      [<a href="https://youtu.be/iWea12EAu6U">video</a>]
      <br>
      [<a href="readings/cs224n-2019-notes05-LM_RNN.pdf">notes (lectures 6 and 7)</a>]
    </td>

    <td>
      Suggested Readings:
      <ol>
        <li><a href="https://web.stanford.edu/~jurafsky/slp3/3.pdf">N-gram Language Models</a> (textbook chapter)</li>
        <li><a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">The Unreasonable Effectiveness of Recurrent Neural Networks</a> (blog post overview)</li>
        <!-- <li><a href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/">Recurrent Neural Networks Tutorial</a> (practical guide)</li> -->
        <li><a href="http://www.deeplearningbook.org/contents/rnn.html">Sequence Modeling: Recurrent and Recursive Neural Nets</a> (Sections 10.1 and 10.2)</li>
	<li><a href="http://norvig.com/chomsky.html">On Chomsky and the Two Cultures of Statistical Learning</a>
      </ol>
    </td>
    <td></td>
    <td></td>
  </tr>

  <tr>
    <td>Tue Jan 29</td>
    <td>Vanishing Gradients and Fancy RNNs
      <br>
      [<a href="slides/cs224n-2019-lecture07-fancy-rnn.pdf">slides</a>]
      [<a href="https://youtu.be/QEw0qEa0E50">video</a>]
      <br>
		  [<a href="readings/cs224n-2019-notes05-LM_RNN.pdf">notes (lectures 6 and 7)</a>]
    </td>
    <td>
      Suggested Readings:
      <ol>
        <li><a href="http://www.deeplearningbook.org/contents/rnn.html">Sequence Modeling: Recurrent and Recursive Neural Nets</a> (Sections 10.3, 10.5, 10.7-10.12)</li>
        <li><a href="http://ai.dinfo.unifi.it/paolo//ps/tnn-94-gradient.pdf">Learning long-term dependencies with gradient descent is difficult</a> (one of the original vanishing gradient papers)</li>
        <li><a href="https://arxiv.org/pdf/1211.5063.pdf">On the difficulty of training Recurrent Neural Networks</a> (proof of vanishing gradient problem)</li>
        <li><a href="https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1174/lectures/vanishing_grad_example.html">Vanishing Gradients Jupyter Notebook</a> (demo for feedforward networks)</li>
        <li><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/">Understanding LSTM Networks</a> (blog post overview)</li>
        <!-- <li><a href="https://arxiv.org/pdf/1504.00941.pdf">A simple way to initialize recurrent networks of rectified linear units</a></li> -->
      </ol>
    </td>
    <td>Assignment 4 <b><font color="green">out</font></b>
        <br>
        [<a href="assignments/a4.zip">code</a>]
        [<a href="assignments/a4.pdf">handout</a>]
        [<a href="https://docs.google.com/document/d/1MHaQvbtPkfEGc93hxZpVhkKum1j_F1qsyJ4X0vktUDI/edit">Azure Guide</a>]
        [<a href="https://docs.google.com/document/d/1z9ST0IvxHQ3HXSAOmpcVbFU5zesMeTtAc9km6LAPJxk/edit">Practical Guide to VMs</a>]
    </td>
    <td>Assignment 3 <b><font color="red">due</font></b></td>
  </tr>

  <tr>
    <td>Thu Jan 31</td>
    <td>Machine Translation, Seq2Seq and Attention
      <br>
      [<a href="slides/cs224n-2019-lecture08-nmt.pdf">slides</a>]
      [<a href="https://youtu.be/XXtpJxZBa2c">video</a>]
      [<a href="readings/cs224n-2019-notes06-NMT_seq2seq_attention.pdf">notes</a>]
    </td>
    <td>
      Suggested Readings:
      <ol>
        <li><a href="https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1162/syllabus.shtml">Statistical Machine Translation slides, CS224n 2015</a> (lectures 2/3/4)</li>
        <li><a href="https://www.cambridge.org/core/books/statistical-machine-translation/94EADF9F680558E13BE759997553CDE5">Statistical Machine Translation</a> (book by Philipp Koehn)</li>
        <li><a href="https://www.aclweb.org/anthology/P02-1040.pdf">BLEU</a> (original paper)</li>
        <li><a href="https://arxiv.org/pdf/1409.3215.pdf">Sequence to Sequence Learning with Neural Networks</a> (original seq2seq NMT paper)</a></li>
        <li><a href="https://arxiv.org/pdf/1211.3711.pdf">Sequence Transduction with Recurrent Neural Networks</a> (early seq2seq speech recognition paper)</li>
        <li><a href="https://arxiv.org/pdf/1409.0473.pdf">Neural Machine Translation by Jointly Learning to Align and Translate</a> (original seq2seq+attention paper)</li>
        <li><a href="https://distill.pub/2016/augmented-rnns/">Attention and Augmented Recurrent Neural Networks</a> (blog post overview)</li>
        <li><a href="https://arxiv.org/pdf/1703.03906.pdf">Massive Exploration of Neural Machine Translation Architectures</a> (practical advice for hyperparameter choices)</li>
      </ol>
    </td>
    <td></td>
    <td></td>
  </tr>

  <tr>
    <td>Tue Feb 5</td>
    <td>
      Practical Tips for Final Projects
      <br>
      [<a href="slides/cs224n-2019-lecture09-final-projects.pdf">slides</a>]
      [<a href="https://youtu.be/fyqm8fRDgl0">video</a>]
      [<a href="readings/final-project-practical-tips.pdf">notes</a>]
    </td>
    <td>
      Suggested Readings:
      <ol>
        <li><a href="https://www.deeplearningbook.org/contents/guidelines.html">Practical Methodology</a> (<i>Deep Learning</i> book chapter)</li>
      </ol>
    </td>
    <td></td>
    <td></td>
  </tr>

  <tr>
    <td>Thu Feb 7</td>
    <td>Question Answering and the Default Final Project<br>
    [<a href="slides/cs224n-2019-lecture10-QA.pdf">slides</a>]
    [<a href="https://youtu.be/yIdF-17HwSk">video</a>]
    [<a href="readings/cs224n-2019-notes07-QA.pdf">notes</a>]
  </td>
    <td>
    </td>
    <td>
      Project Proposal <b><font color="green">out</font></b>
      <br>
      [<a href="project/project-proposal-instructions.pdf">instructions</a>]
      <br><br>
      Default Final Project <b><font color="green">out</font></b>
      [<a href="project/default-final-project-handout.pdf">handout</a>] [<a href="https://github.com/chrischute/squad">code</a>]
    </td>
    <td>Assignment 4 <b><font color="red">due</font></b></td>
  </tr>

  <tr>
    <td>Tue Feb 12</td>
    <td>ConvNets for NLP <br>
    [<a href="slides/cs224n-2019-lecture11-convnets.pdf">slides</a>]
    [<a href="https://youtu.be/EAJoRA0KX7I">video</a>]
    [<a href="readings/cs224n-2019-notes08-CNN.pdf">notes</a>]
    </td>
    <td>
      Suggested Readings:
      <ol>
        <!-- <li><a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a></li>
        <li><a href="https://arxiv.org/pdf/1607.06450.pdf">Layer Normalization</a></li> -->
        <li><a href="https://arxiv.org/abs/1408.5882">Convolutional Neural Networks for Sentence Classification</a></li>
        <!-- <li><a href="https://arxiv.org/abs/1207.0580">Improving neural networks by preventing co-adaptation of feature detectors</a></li> -->
        <li><a href="https://arxiv.org/pdf/1404.2188.pdf">A Convolutional Neural Network for Modelling Sentences</a></li>
      </ol>
    </td>
    <td></td>
    <td></td>
  </tr>

  <tr>
    <td>Thu Feb 14</td>
    <td>Information from parts of words: Subword Models
    <br>
    [<a href="slides/cs224n-2019-lecture12-subwords.pdf">slides</a>]
    [<a href="https://youtu.be/9oTHFx0Gg3Q">video</a>]
    </td>
    <td>Suggested readings:
      <ol>
	<li>
           Minh-Thang Luong and Christopher Manning. <a href="https://arxiv.org/abs/1604.00788">Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models</a>
	 </li>
      </ol>
    </td>
    <td>
      Assignment 5 <b><font color="green">out</font></b>
      <br>
      [<a href="https://stanford.box.com/s/t4nlmcc08t9k6mflz6sthjlmjs7lip6p">original code (requires Stanford login)</a> / <a href="assignments/a5_public.zip">public version</a>]
      [<a href="assignments/a5.pdf">handout</a>]
    </td>
    <td>Project Proposal <b><font color="red">due</font></b></td>
  </tr>

  <tr>
    <td>Tue Feb 19</td>
    <td>Modeling contexts of use: Contextual Representations and Pretraining
      <br>
      [<a href="slides/cs224n-2019-lecture13-contextual-representations.pdf">slides</a>]
      [<a href="https://youtu.be/S-CspeZ8FHc">video</a>]
    </td>
    <td>Suggested readings:
      <ol>
	       <li>
           Smith, Noah A. <a href="https://arxiv.org/abs/1902.06006">Contextual Word Representations: A Contextual Introduction</a>. (Published just in time for this lecture!)
         </li>
	 <li><a href="http://jalammar.github.io/illustrated-bert/">The
	 Illustrated BERT, ELMo, and co.</a>
	 </li>
      </ol>
    </td>
    <td></td>
    <td></td>
  </tr>

  <tr>
    <td>Thu Feb 21</td>
    <td>
      Transformers and Self-Attention For Generative Models
      <br>
      <i>(guest lecture by <a href="https://ai.google/research/people/AshishVaswani">Ashish Vaswani</a> and <a href="https://ai.google/research/people/105787">Anna Huang</a>)</i>
      <br>
      [<a href="slides/cs224n-2019-lecture14-transformers.pdf">slides</a>]
      [<a href="https://youtu.be/5vcj8kSwBCY">video</a>]
    </td>
    <td>Suggested readings:
      <ol>
	       <li><a href="https://arxiv.org/pdf/1706.03762.pdf">Attention is all you need</a></li>
         <li><a href="https://arxiv.org/pdf/1802.05751.pdf">Image Transformer</a></li>
         <li><a href="https://arxiv.org/pdf/1809.04281.pdf">Music Transformer: Generating music with long-term structure</a></li>
      </ol>
    </td>
    <td></td>
    <td></td>
  </tr>

  <tr class="warning">
    <td>Fri Feb 22</td>
    <td></td>
    <td></td>
    <td>
      Project Milestone <b><font color="green">out</font></b>
      <br>
      [<a href="project/project-milestone-instructions.pdf">instructions</a>]
    </td>
    <td>Assignment 5 <b><font color="red">due</font></b></td>
  </tr>

  <tr>
    <td>Tue Feb 26</td>
    <td>
      Natural Language Generation
      <br>
      [<a href="slides/cs224n-2019-lecture15-nlg.pdf">slides</a>]
      [<a href="https://youtu.be/4uG1NMKNWCU">video</a>]
    </td>
    <td></td>
    <td></td>
    <td></td>
  </tr>

  <tr>
    <td>Thu Feb 28</td>
    <td>Reference in Language and Coreference Resolution
      <br>
      [<a href="slides/cs224n-2019-lecture16-coref.pdf">slides</a>]
      [<a href="https://youtu.be/i19m4GzBhfc">video</a>]
    </td>
    <td></td>
    <td></td>
    <td></td>
  </tr>

  <tr>
    <td>Tue Mar 5</td>
    <td>Multitask Learning: A general model for NLP? <i>(guest lecture by <a href="https://www.socher.org/">Richard Socher</a>)</i>
      <br>
      <!-- [<a href="https://drive.google.com/file/d/1IvuJNtaoS3F0CmPpO0Brx7jUSLB21pqt/view?usp=drive_web">slides</a>] -->
      [<a href="slides/cs224n-2019-lecture17-multitask.pdf">slides</a>]
      [<a href="https://youtu.be/M8dsZsEtEsg">video</a>]
    </td>
    <td></td>
    <td></td>
    <td>Project Milestone <b><font color="red">due</font></b></td>
  </tr>

  <tr>
    <td>Thu Mar 7</td>
    <td>
      Constituency Parsing and Tree Recursive Neural Networks
      <br>
      [<a href="slides/cs224n-2019-lecture18-TreeRNNs.pdf">slides</a>]
      [<a href="https://youtu.be/6Z4A3RSf-HY">video</a>]
      [<a href="readings/cs224n-2019-notes09-RecursiveNN_constituencyparsing.pdf">notes</a>]
    </td>
    <td>
      Suggested Readings:
      <ol>
        <li><a href="http://www.aclweb.org/anthology/P13-1045">Parsing with Compositional Vector Grammars.</a></li>
        <li><a href="https://arxiv.org/pdf/1805.01052.pdf">Constituency Parsing with a Self-Attentive Encoder</a></li>
      </ol>
    </td>
    <td></td>
    <td></td>
  </tr>

  <tr>
    <td>Tue Mar 12</td>
    <td>
      Safety, Bias, and Fairness <i>(guest lecture by <a href="http://www.m-mitchell.com/">Margaret Mitchell</a>)</i>
      <br>
      [<a href="slides/cs224n-2019-lecture19-bias.pdf">slides</a>]
      [<a href="https://youtu.be/XR8YSRcuVLE">video</a>]
    </td>
    <td></td>
    <td></td>
    <td></td>
  </tr>

  <tr>
    <td>Thu Mar 14</td>
    <td>
      Future of NLP + Deep Learning
      <br>
      [<a href="slides/cs224n-2019-lecture20-future.pdf">slides</a>]
      [<a href="https://youtu.be/3wWZBGN-iX8">video</a>]
    </td>
    <td></td>
    <td></td>
    <td></td>
  </tr>

  <tr class="warning">
    <td>Sun Mar 17</td>
    <td></td>
    <td></td>
    <td></td>
    <td>
      <b>Final Project Report <font color="red">due</font></b>
      [<a href="project/project-report-instructions.pdf">instructions</a>]
    </td>
  </tr>

  <tr class="warning">
    <td>Wed Mar 20</td>
    <td><b>Final project poster session</b>
    <br>
    [<a href="https://www.facebook.com/events/1218481914969541">details</a>]
    </td>
    <td>5:15 - 8:30pm <br>McCaw Hall at the Alumni Center [<a href="https://alumni.stanford.edu/get/page/resources/alumnicenter/directions">map</a>]
    </td>
    <td></td>
    <td>
      <b>Project Poster/Video <font color="red">due</font></b>
      [<a href="project/project-postervideo-instructions.pdf">instructions</a>]
    </td>
  </tr>
  </tbody>
</table>
</div>

</div>
</body>

</html>
